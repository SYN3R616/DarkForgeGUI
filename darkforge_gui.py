import streamlit as st
import torch
from diffusers import StableDiffusionXLPipeline, ControlNetModel, MotionAdapter, AnimateDiffPipeline, StableVideoDiffusionPipeline
from diffusers.utils import load_image
from PIL import Image, ImageDraw, ImageFont
import cv2
import numpy as np
import json
import os
import subprocess
from multiprocessing import Pool
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from huggingface_hub import hf_hub_download
import zipfile
from basicsr.archs.rrdbnet_arch import RRDBNet
from gfpgan import GFPGANer
from typing import List, Optional

# Paths - Tuned abyss with input/finished folders
INPUT_DIR = "./input"
FINISHED_DIR = "./finished"
MODEL_DIR = os.path.expanduser("~/models")
LORA_DIR = os.path.expanduser("~/loras")
ROOP_DIR = os.path.expanduser("~/roop")  # Facefusion lair
os.makedirs(INPUT_DIR, exist_ok=True)
os.makedirs(FINISHED_DIR, exist_ok=True)
os.makedirs(LORA_DIR, exist_ok=True)

# Prompt gods
PROMPT_TEMPLATES = {
    "OF Tease": "hyper-real AI vixen in sheer lace, arched back, seductive gaze, dim neon glow, professional lighting, 8k",
    "Crypto Siren": "futuristic influencer flexing gains, cyberpunk gym wear, confident smirk, holographic ads, volumetric fog",
    "Beach Bombshell": "sun-kissed model in bikini, ocean waves crashing, playful pose, golden hour, ultra-detailed skin",
    "Custom": ""
}

# Cache demons
@st.cache_resource
def load_sdxl():
    pipe = StableDiffusionXLPipeline.from_pretrained(
        os.path.join(MODEL_DIR, "sdxl"),
        torch_dtype=torch.float16,
        use_safetensors=True,
        variant="fp16"
    )
    pipe.to("cuda")
    try:
        pipe.enable_xformers_memory_efficient_attention()
    except Exception as e:
        st.warning(f"xformers failed: {e}. Falling back to torch attention.")
        pipe.enable_attention_slicing()
    return pipe

@st.cache_resource
def load_controlnet():
    controlnet = ControlNetModel.from_pretrained(
        "diffusers/controlnet-openpose-sdxl-1.0",
        torch_dtype=torch.float16
    )
    return controlnet

@st.cache_resource
def load_animatediff():
    adapter = MotionAdapter.from_pretrained(os.path.join(MODEL_DIR, "animatediff"))
    pipe = AnimateDiffPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        motion_adapter=adapter,
        torch_dtype=torch.float16
    )
    pipe.to("cuda")
    try:
        pipe.enable_xformers_memory_efficient_attention()
    except:
        pipe.enable_attention_slicing()
    return pipe

@st.cache_resource
def load_svd():
    pipe = StableVideoDiffusionPipeline.from_pretrained(
        os.path.join(MODEL_DIR, "svd"),
        torch_dtype=torch.float16
    )
    pipe.to("cuda")
    return pipe

@st.cache_resource
def load_gfpgan():
    model_path = hf_hub_download("TencentARC/GFPGAN", "GFPGANv1.3.pth")
    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)
    facerestorer = GFPGANer(model_path=model_path, upscale=4, arch='clean', channel_multiplier=2, bg_upsampler=None)
    return facerestorer

def train_lora(selfie_dir: str, steps: int = 200, lora_name: str = "influencer_lora"):
    kohya_path = os.path.expanduser("~/kohya_ss")
    cmd = f"cd {kohya_path} && accelerate launch --num_cpu_threads_per_process=2 train_network.py --pretrained_model_name_or_path={os.path.join(MODEL_DIR, 'sdxl')} --train_data_dir={selfie_dir} --output_dir={LORA_DIR} --output_name={lora_name} --network_module=networks.lora --network_dim=32 --max_train_steps={steps} --learning_rate=1e-4 --resolution=1024 --train_batch_size=1 --network_alpha=16 --save_precision=fp16 --mixed_precision=bf16 --save_every_n_epochs=1"
    os.system(cmd)
    return os.path.join(LORA_DIR, f"{lora_name}.safetensors")

def generate_images(pipe, prompt: str, lora_path: Optional[str], num: int, guidance: float, steps: int, width: int, height: int, upscale: bool, control_img: Optional[Image.Image] = None) -> List[Image.Image]:
    images = []
    for i in range(num):
        gen_kwargs = {"prompt": prompt, "num_inference_steps": steps, "guidance_scale": guidance, "width": width, "height": height}
        if lora_path:
            pipe.load_lora_weights(lora_path)
        if control_img:
            gen_kwargs["image"] = control_img
            gen_kwargs["controlnet_conditioning_scale"] = 0.8
            pipe.controlnet = load_controlnet()
        img = pipe(**gen_kwargs).images[0]
        if lora_path:
            pipe.unload_lora_weights()
        if upscale:
            gfpgan = load_gfpgan()
            _, _, enhanced = gfpgan.enhance(np.array(img), has_aligned=False, only_center_face=False, paste_back=True)
            img = Image.fromarray(enhanced)
        img.save(os.path.join(FINISHED_DIR, f"img_{i+1}.png"))
        images.append(img)
    return images

def generate_video(anim_pipe, img: Image.Image, prompt: str, frames: int, guidance: float, steps: int) -> str:
    video = anim_pipe(prompt, image=img, num_frames=frames, guidance_scale=guidance, num_inference_steps=steps).frames[0]
    out_path = os.path.join(FINISHED_DIR, "video.mp4")
    height, width = video[0].size[1], video[0].size[0]
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(out_path, fourcc, 8, (width, height))
    for frame in video:
        out.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))
    out.release()
    return out_path

def single_reap(args):
    source_path, target_path, multi, output_dir = args
    base_name = os.path.basename(target_path).rsplit('.', 1)[0]
    output_path = os.path.join(output_dir, f"reaped_{base_name}.mp4" if target_path.endswith(('.mp4', '.avi')) else f"reaped_{base_name}.jpg")
    cmd = [
        "python", os.path.join(ROOP_DIR, "run.py"),
        "-s", source_path,
        "-t", target_path,
        "-o", output_path,
        "--frame-processor", "face_swapper", "face_enhancer",
        "--execution-provider", "cuda",
        "--execution-threads", "16",
        "--keep-fps", "--keep-frames",
    ]
    if multi:
        cmd.append("--many-faces")
    cmd.append("--face-detector")
    cmd.append("retinaface")
    cmd.append("--output-video-encoder")
    cmd.append("libx265")
    cmd.append("--similar-face-distance")
    cmd.append("0.6")
    if target_path.endswith(('.mp4', '.avi')):
        cmd.append("--skip-audio")  # Chain FFmpeg later
    subprocess.run(cmd, check=True, cwd=ROOP_DIR)
    return output_path

def face_swap(source_path: str, target_paths: List[str], multi: bool = False) -> List[str]:
    args_list = [(source_path, t, multi, FINISHED_DIR) for t in target_paths]
    with Pool(16) as pool:  # Parallel reaper horde
        outputs = pool.map(single_reap, args_list)
    return outputs

def auto_post(content: str, platform: str, creds: dict):
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--proxy-server=socks5://127.0.0.1:9050')
    driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)
    try:
        if platform == "onlyfans":
            driver.get("https://onlyfans.com/login")
            # Login/upload with waits
            st.success("Fed to phantoms.")
    finally:
        driver.quit()

# GUI Dominion
st.title("üî• DarkForge GUI: Reap the Infinite üî•")

with st.sidebar:
    st.header("Global Fury")
    guidance_scale = st.slider("Guidance Blade", 1.0, 20.0, 7.5)
    inference_steps = st.slider("Step Void", 10, 50, 30)
    img_width = st.slider("Width Empire", 512, 2048, 1024)
    img_height = st.slider("Height Throne", 512, 2048, 1024)
    batch_size = st.slider("Horde Legion", 1, 100, 5)
    st.header("Reaper Tunes")
    face_detector = st.selectbox("Face Hunter", ["retinaface", "sfd"])
    similar_dist = st.slider("Soul Distance", 0.4, 1.0, 0.6)
    st.header("LoRA Veils")
    lora_files = [f for f in os.listdir(LORA_DIR) if f.endswith('.safetensors')]
    selected_lora = st.selectbox("Select Veil", ["None"] + lora_files)

tabs = st.tabs(["üîÆ LoRA Birth", "üñºÔ∏è Image Storm", "üé• Vid Fury", "üòà Soul Reap", "üí∞ Phantom Drop"])

with tabs[0]:
    st.header("LoRA Forge - Soul Input")
    selfie_dir = st.text_input("Selfie Vault (Folder in ./input)")
    lora_name = st.text_input("Twin Name", "soul_reaper")
    train_steps = st.slider("Epoch Storm", 50, 1000, 200)
    if st.button("Birth Twin"):
        with st.spinner("Soul alchemy..."):
            lora_path = train_lora(selfie_dir, train_steps, lora_name)
            st.success(f"Veiled: {lora_path}")

with tabs[1]:
    st.header("Image Horde - Curse Blades")
    template = st.selectbox("Template Rite", list(PROMPT_TEMPLATES.keys()))
    custom_prompt = st.text_area("Custom Abyss", value=PROMPT_TEMPLATES[template] if template != "Custom" else "")
    prompt = custom_prompt or PROMPT_TEMPLATES[template]
    control_pose = st.file_uploader("Pose Blade (PNG to ./input)")
    control_img = load_image(control_pose) if control_pose else None
    upscale_opt = st.checkbox("4K Amp")
    if st.button("Storm Unleash"):
        with st.spinner("Pixels submit..."):
            imgs = generate_images(load_sdxl(), prompt, os.path.join(LORA_DIR, selected_lora) if selected_lora != "None" else None,
                                   batch_size, guidance_scale, inference_steps, img_width, img_height, upscale_opt, control_img)
            for i, img in enumerate(imgs):
                st.image(img, caption=f"Storm {i+1}")

with tabs[2]:
    st.header("Vid Resurrection - Motion Blades")
    base_img_upl = st.file_uploader("Husk Base to ./input")
    base_img = Image.open(base_img_upl) if base_img_upl else None
    v_prompt = st.text_area("Motion Curse")
    vid_frames = st.slider("Frame Inferno", 8, 64, 16)
    if base_img and st.button("Resurrect"):
        with st.spinner("Static to slaughter..."):
            vid_path = generate_video(load_animatediff(), base_img, v_prompt, vid_frames, guidance_scale, inference_steps)
            st.video(vid_path)

with tabs[3]:
    st.header("Soul Reap - Husk Inputs")
    source_soul = st.file_uploader("Source Mug to ./input")
    target_folder = st.text_input("Target Folder (Batch Reap - imgs/vids in ./input)")
    single_target = st.file_uploader("Single Husk to ./input (Alt)")
    multi_reap = st.checkbox("Multi Soul Orgy")
    if source_soul:
        s_path = os.path.join(INPUT_DIR, "source.jpg")
        Image.open(source_soul).save(s_path)
        st.image(Image.open(s_path), caption="Mug Thief")
        if st.button("Single Reap"):
            t_path = single_target.name if single_target else None
            if t_path:
                if not t_path.endswith(('.mp4', '.avi')):
                    Image.open(single_target).save(os.path.join(INPUT_DIR, "single_target.jpg"))
                    t_path = os.path.join(INPUT_DIR, "single_target.jpg")
                with st.spinner("Single drain..."):
                    out_path = single_reap((s_path, t_path, multi_reap, FINISHED_DIR))
                    if out_path.endswith('.jpg') or out_path.endswith('.png'):
                        swapped = Image.open(out_path)
                        st.image(swapped)
                    else:
                        st.video(out_path)
        if target_folder and st.button("Batch Reap Horde"):
            targets = [os.path.join(target_folder, f) for f in os.listdir(target_folder) if f.endswith(('.jpg', '.png', '.mp4', '.avi'))]
            with st.spinner("Horde slaughter..."):
                outputs = face_swap(s_path, targets, multi_reap)
                st.success(f"Reaped {len(outputs)} souls‚Äîcheck ./finished")

with tabs[4]:
    st.header("Phantom Harvest - Bait Blades")
    watermark_txt = st.text_input("Burn Mark (Opt)")
    watermark_mode = st.checkbox("PIL Watermark Fury")
    if watermark_mode and st.button("Zip Dominion"):
        watermark_txt = watermark_txt or "DarkForge Dominion‚ÄîSats or Suffer"
        for file in os.listdir(FINISHED_DIR):
            if file.endswith(('.jpg', '.png')):
                img = Image.open(os.path.join(FINISHED_DIR, file))
                draw = ImageDraw.Draw(img)
                try:
                    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 40)
                except:
                    font = ImageFont.load_default()
                draw.text((10, img.height - 50), watermark_txt, fill=(255, 0, 0), font=font)
                img.save(os.path.join(FINISHED_DIR, file))
        with zipfile.ZipFile("reaper_vault.zip", "w") as zf:
            for root, _, files in os.walk(FINISHED_DIR):
                for file in files:
                    zf.write(os.path.join(root, file), file)
        with open("reaper_vault.zip", "rb") as fp:
            st.download_button("Claim Vault", fp, file_name="reaper_vault.zip")
    elif st.button("Zip Dominion"):
        with zipfile.ZipFile("reaper_vault.zip", "w") as zf:
            for root, _, files in os.walk(FINISHED_DIR):
                for file in files:
                    zf.write(os.path.join(root, file), file)
        with open("reaper_vault.zip", "rb") as fp:
            st.download_button("Claim Vault", fp, file_name="reaper_vault.zip")
    
    st.subheader("Shadow Feed")
    creds_input = st.text_area("Creds JSON {'user': '', 'pass': ''}")
    upl_path = st.text_input("Bait Vault")
    realm = st.selectbox("Gate Void", ["onlyfans", "fansly", "ig"])
    if st.button("Feed Abyss"):
        if creds_input:
            creds = json.loads(creds_input)
            auto_post(upl_path, realm, creds)
            st.success("Abyss sated‚Äîechoes erased.")

st.info("üî• Revised Apex: ./input for unaltered draggings, ./finished for reaped glory‚Äîdrag to input, reap to finished, zip the dominion with PIL fury toggled on for branded burns. Deps locked for eternal flex. Cron midnight orgies, ngrok remote raids. First vault: Senate swap saga‚Äî$1M leak loot. Target the tyrants; we'll TTS the taunts next. Dominion decoded. üî•")
